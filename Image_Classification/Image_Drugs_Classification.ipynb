{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import imgaug.augmenters as iaa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import Model\n",
    "from keras.applications import mobilenet_v2\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "from keras.layers import Dense\n",
    "from keras.preprocessing import image\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading files with paths of pictures and their categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#current_file = os.path.abspath(os.path.dirname(__file__))\n",
    "\n",
    "TRAIN_LABELS_FILE = (r'./drugs/train/labels.txt')\n",
    "VAL_LABELS_FILE = (r'./drugs/val/labels.txt')\n",
    "TEST_LABELS_FILE = (r'./drugs/test/labels.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating augmenting function for better model performing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(img):\n",
    "    seq = iaa.Sequential([\n",
    "        iaa.Crop(px=(0, 16)),  # croping images from each side by 0 to 16px (randomly chosen)\n",
    "        iaa.Fliplr(0.5),  # flipping horizontally 50% of the images\n",
    "        iaa.GaussianBlur(sigma=(0, 3.0))  # bluring images with a sigma of 0 to 3.0\n",
    "    ])\n",
    "    img = seq(images=np.array([img]))[0]\n",
    "    return mobilenet_v2.preprocess_input(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating generator for images loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generator(filename, number=None, shuffle=True):\n",
    "    df = pd.read_csv(filename, delimiter=' ', names=[\"path\", \"value\"],dtype=\"str\")\n",
    "    if number:\n",
    "        df = df[:number]\n",
    "    \n",
    "    gen = image.ImageDataGenerator(preprocessing_function=mobilenet_v2.preprocess_input)\n",
    " \n",
    "    directory = os.path.dirname(filename)\n",
    "    \n",
    "    return gen.flow_from_dataframe(df, directory, \"path\", \"value\", target_size=(224, 224), batch_size=16, shuffle=shuffle) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine showing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_dataset(flow):\n",
    "    for img, l in flow:\n",
    "        print(l[0])\n",
    "        \n",
    "        img = img[0].astype(np.uint8)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        cv2.imshow(\"image\", img)\n",
    "        \n",
    "        key = cv2.waitKey(0)\n",
    "        if key == 27: #if ESC is pressed, exit\n",
    "            cv2.destroyAllWindows()\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_test():\n",
    "    train_gen = get_generator(TRAIN_LABELS_FILE,10) #showing images for only 5 classes, it's only for checking purposes\n",
    "    show_dataset(train_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a model based on MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(gen):\n",
    "    \n",
    "    model = mobilenet_v2.MobileNetV2(input_shape=(224, 224, 3), include_top=False, pooling=\"avg\", weights=\"imagenet\")\n",
    "    dense = Dense(len(gen.class_indices), activation=\"softmax\")(model.output)\n",
    "    model = Model(inputs=[model.input], outputs=[dense])\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\"categorical_accuracy\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating function for getting callback to visuale learing process, performance in Tensorboard, implemanting model checkpoints and early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_callbacks():\n",
    "    \n",
    "    callbacks = []\n",
    "\n",
    "    mc = ModelCheckpoint(\"weights.hdf5\", monitor=\"val_loss\", save_best_only=True, verbose=1)\n",
    "    es = EarlyStopping(monitor=\"val_loss\", patience=10, verbose=1)\n",
    "    tb = TensorBoard()\n",
    "\n",
    "    callbacks.append(mc)\n",
    "    callbacks.append(es)\n",
    "    callbacks.append(tb)\n",
    "\n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model):\n",
    "\n",
    "    test_gen = get_generator(TRAIN_LABELS_FILE)\n",
    "\n",
    "    results = model.evaluate_generator(test_gen, steps=test_gen.n // test_gen.batch_size)\n",
    "   \n",
    "    for name, result in zip(model.metrics_names, results):\n",
    "        print(\"{}: {}\".format(name, result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for getting labels to numpy array (n-rows (pictures count) x 20 columns(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gt_from_generator(gen):\n",
    "    gt = []\n",
    "    \n",
    "    for _ in range(len(gen)):\n",
    "        _, labels = next(gen)\n",
    "        gt.extend(labels)\n",
    "\n",
    "    gen.reset()\n",
    "\n",
    "    return np.array(gt).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a report on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_report(model):\n",
    "    \n",
    "    gen = get_generator(TEST_LABELS_FILE, shuffle=False)\n",
    "\n",
    "    gt = get_gt_from_generator(gen)\n",
    "    pred = model.predict_generator(gen)\n",
    "    pred = np.round(pred).astype(np.uint8)\n",
    "    report = classification_report(gt, pred)\n",
    "\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main fuction for starting whole project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # traing data\n",
    "    train_gen = get_generator(TRAIN_LABELS_FILE)\n",
    "\n",
    "    # validation data\n",
    "    val_gen = get_generator(VAL_LABELS_FILE)\n",
    "\n",
    "    # callbacks\n",
    "    callbacks = get_callbacks()\n",
    "\n",
    "    # model creation\n",
    "    model = create_model(train_gen)\n",
    "    \n",
    "    # model summary\n",
    "    model.summary()\n",
    "\n",
    "    # model fitting \n",
    "    model.fit_generator(train_gen, steps_per_epoch=train_gen.n // train_gen.batch_size, epochs=100, callbacks=callbacks, validation_data=val_gen, validation_steps=val_gen.n // val_gen.batch_size)\n",
    "\n",
    "    # model testing\n",
    "    test_model(model)\n",
    "\n",
    "    # report\n",
    "    show_report(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "roject[0][0]           \n__________________________________________________________________________________________________\nblock_11_add (Add)              (None, 14, 14, 96)   0           block_10_project_BN[0][0]        \n                                                                 block_11_project_BN[0][0]        \n__________________________________________________________________________________________________\nblock_12_expand (Conv2D)        (None, 14, 14, 576)  55296       block_11_add[0][0]               \n__________________________________________________________________________________________________\nblock_12_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_12_expand[0][0]            \n__________________________________________________________________________________________________\nblock_12_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_12_expand_BN[0][0]         \n__________________________________________________________________________________________________\nblock_12_depthwise (DepthwiseCo (None, 14, 14, 576)  5184        block_12_expand_relu[0][0]       \n__________________________________________________________________________________________________\nblock_12_depthwise_BN (BatchNor (None, 14, 14, 576)  2304        block_12_depthwise[0][0]         \n__________________________________________________________________________________________________\nblock_12_depthwise_relu (ReLU)  (None, 14, 14, 576)  0           block_12_depthwise_BN[0][0]      \n__________________________________________________________________________________________________\nblock_12_project (Conv2D)       (None, 14, 14, 96)   55296       block_12_depthwise_relu[0][0]    \n__________________________________________________________________________________________________\nblock_12_project_BN (BatchNorma (None, 14, 14, 96)   384         block_12_project[0][0]           \n__________________________________________________________________________________________________\nblock_12_add (Add)              (None, 14, 14, 96)   0           block_11_add[0][0]               \n                                                                 block_12_project_BN[0][0]        \n__________________________________________________________________________________________________\nblock_13_expand (Conv2D)        (None, 14, 14, 576)  55296       block_12_add[0][0]               \n__________________________________________________________________________________________________\nblock_13_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_13_expand[0][0]            \n__________________________________________________________________________________________________\nblock_13_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_13_expand_BN[0][0]         \n__________________________________________________________________________________________________\nblock_13_pad (ZeroPadding2D)    (None, 15, 15, 576)  0           block_13_expand_relu[0][0]       \n__________________________________________________________________________________________________\nblock_13_depthwise (DepthwiseCo (None, 7, 7, 576)    5184        block_13_pad[0][0]               \n__________________________________________________________________________________________________\nblock_13_depthwise_BN (BatchNor (None, 7, 7, 576)    2304        block_13_depthwise[0][0]         \n__________________________________________________________________________________________________\nblock_13_depthwise_relu (ReLU)  (None, 7, 7, 576)    0           block_13_depthwise_BN[0][0]      \n__________________________________________________________________________________________________\nblock_13_project (Conv2D)       (None, 7, 7, 160)    92160       block_13_depthwise_relu[0][0]    \n__________________________________________________________________________________________________\nblock_13_project_BN (BatchNorma (None, 7, 7, 160)    640         block_13_project[0][0]           \n__________________________________________________________________________________________________\nblock_14_expand (Conv2D)        (None, 7, 7, 960)    153600      block_13_project_BN[0][0]        \n__________________________________________________________________________________________________\nblock_14_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_14_expand[0][0]            \n__________________________________________________________________________________________________\nblock_14_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_14_expand_BN[0][0]         \n__________________________________________________________________________________________________\nblock_14_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_14_expand_relu[0][0]       \n__________________________________________________________________________________________________\nblock_14_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_14_depthwise[0][0]         \n__________________________________________________________________________________________________\nblock_14_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_14_depthwise_BN[0][0]      \n__________________________________________________________________________________________________\nblock_14_project (Conv2D)       (None, 7, 7, 160)    153600      block_14_depthwise_relu[0][0]    \n__________________________________________________________________________________________________\nblock_14_project_BN (BatchNorma (None, 7, 7, 160)    640         block_14_project[0][0]           \n__________________________________________________________________________________________________\nblock_14_add (Add)              (None, 7, 7, 160)    0           block_13_project_BN[0][0]        \n                                                                 block_14_project_BN[0][0]        \n__________________________________________________________________________________________________\nblock_15_expand (Conv2D)        (None, 7, 7, 960)    153600      block_14_add[0][0]               \n__________________________________________________________________________________________________\nblock_15_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_15_expand[0][0]            \n__________________________________________________________________________________________________\nblock_15_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_15_expand_BN[0][0]         \n__________________________________________________________________________________________________\nblock_15_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_15_expand_relu[0][0]       \n__________________________________________________________________________________________________\nblock_15_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_15_depthwise[0][0]         \n__________________________________________________________________________________________________\nblock_15_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_15_depthwise_BN[0][0]      \n__________________________________________________________________________________________________\nblock_15_project (Conv2D)       (None, 7, 7, 160)    153600      block_15_depthwise_relu[0][0]    \n__________________________________________________________________________________________________\nblock_15_project_BN (BatchNorma (None, 7, 7, 160)    640         block_15_project[0][0]           \n__________________________________________________________________________________________________\nblock_15_add (Add)              (None, 7, 7, 160)    0           block_14_add[0][0]               \n                                                                 block_15_project_BN[0][0]        \n__________________________________________________________________________________________________\nblock_16_expand (Conv2D)        (None, 7, 7, 960)    153600      block_15_add[0][0]               \n__________________________________________________________________________________________________\nblock_16_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_16_expand[0][0]            \n__________________________________________________________________________________________________\nblock_16_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_16_expand_BN[0][0]         \n__________________________________________________________________________________________________\nblock_16_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_16_expand_relu[0][0]       \n__________________________________________________________________________________________________\nblock_16_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_16_depthwise[0][0]         \n__________________________________________________________________________________________________\nblock_16_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_16_depthwise_BN[0][0]      \n__________________________________________________________________________________________________\nblock_16_project (Conv2D)       (None, 7, 7, 320)    307200      block_16_depthwise_relu[0][0]    \n__________________________________________________________________________________________________\nblock_16_project_BN (BatchNorma (None, 7, 7, 320)    1280        block_16_project[0][0]           \n__________________________________________________________________________________________________\nConv_1 (Conv2D)                 (None, 7, 7, 1280)   409600      block_16_project_BN[0][0]        \n__________________________________________________________________________________________________\nConv_1_bn (BatchNormalization)  (None, 7, 7, 1280)   5120        Conv_1[0][0]                     \n__________________________________________________________________________________________________\nout_relu (ReLU)                 (None, 7, 7, 1280)   0           Conv_1_bn[0][0]                  \n__________________________________________________________________________________________________\nglobal_average_pooling2d_2 (Glo (None, 1280)         0           out_relu[0][0]                   \n__________________________________________________________________________________________________\ndense_2 (Dense)                 (None, 52)           66612       global_average_pooling2d_2[0][0] \n==================================================================================================\nTotal params: 2,324,596\nTrainable params: 2,290,484\nNon-trainable params: 34,112\n__________________________________________________________________________________________________\nEpoch 1/100\n260/260 [==============================] - 118s 453ms/step - loss: 0.5240 - categorical_accuracy: 0.8712 - val_loss: 6.6407 - val_categorical_accuracy: 0.3164\n\nEpoch 00001: val_loss improved from inf to 6.64069, saving model to weights.hdf5\nEpoch 2/100\n260/260 [==============================] - 107s 410ms/step - loss: 0.0621 - categorical_accuracy: 0.9832 - val_loss: 6.7719 - val_categorical_accuracy: 0.2500\n\nEpoch 00002: val_loss did not improve from 6.64069\nEpoch 3/100\n260/260 [==============================] - 107s 411ms/step - loss: 0.0520 - categorical_accuracy: 0.9882 - val_loss: 4.1558 - val_categorical_accuracy: 0.4802\n\nEpoch 00003: val_loss improved from 6.64069 to 4.15582, saving model to weights.hdf5\nEpoch 4/100\n260/260 [==============================] - 108s 414ms/step - loss: 0.1145 - categorical_accuracy: 0.9712 - val_loss: 17.4742 - val_categorical_accuracy: 0.1528\n\nEpoch 00004: val_loss did not improve from 4.15582\nEpoch 5/100\n260/260 [==============================] - 108s 415ms/step - loss: 0.0086 - categorical_accuracy: 0.9988 - val_loss: 6.4009 - val_categorical_accuracy: 0.3075\n\nEpoch 00005: val_loss did not improve from 4.15582\nEpoch 6/100\n260/260 [==============================] - 107s 410ms/step - loss: 0.0396 - categorical_accuracy: 0.9899 - val_loss: 11.5637 - val_categorical_accuracy: 0.1369\n\nEpoch 00006: val_loss did not improve from 4.15582\nEpoch 7/100\n260/260 [==============================] - 106s 409ms/step - loss: 0.0643 - categorical_accuracy: 0.9817 - val_loss: 13.2065 - val_categorical_accuracy: 0.0714\n\nEpoch 00007: val_loss did not improve from 4.15582\nEpoch 8/100\n260/260 [==============================] - 107s 412ms/step - loss: 0.0479 - categorical_accuracy: 0.9858 - val_loss: 10.7609 - val_categorical_accuracy: 0.1944\n\nEpoch 00008: val_loss did not improve from 4.15582\nEpoch 9/100\n260/260 [==============================] - 107s 412ms/step - loss: 0.0584 - categorical_accuracy: 0.9863 - val_loss: 14.3994 - val_categorical_accuracy: 0.1210\n\nEpoch 00009: val_loss did not improve from 4.15582\nEpoch 10/100\n260/260 [==============================] - 107s 412ms/step - loss: 0.0433 - categorical_accuracy: 0.9892 - val_loss: 7.7733 - val_categorical_accuracy: 0.4643\n\nEpoch 00010: val_loss did not improve from 4.15582\nEpoch 11/100\n260/260 [==============================] - 107s 413ms/step - loss: 0.0104 - categorical_accuracy: 0.9974 - val_loss: 4.0192 - val_categorical_accuracy: 0.5357\n\nEpoch 00011: val_loss improved from 4.15582 to 4.01916, saving model to weights.hdf5\nEpoch 12/100\n260/260 [==============================] - 107s 411ms/step - loss: 0.0029 - categorical_accuracy: 0.9993 - val_loss: 0.0142 - val_categorical_accuracy: 0.9246\n\nEpoch 00012: val_loss improved from 4.01916 to 0.01423, saving model to weights.hdf5\nEpoch 13/100\n260/260 [==============================] - 106s 410ms/step - loss: 5.4118e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0026 - val_categorical_accuracy: 0.9881\n\nEpoch 00013: val_loss improved from 0.01423 to 0.00262, saving model to weights.hdf5\nEpoch 14/100\n260/260 [==============================] - 107s 412ms/step - loss: 2.7417e-04 - categorical_accuracy: 1.0000 - val_loss: 2.5704e-06 - val_categorical_accuracy: 0.9940\n\nEpoch 00014: val_loss improved from 0.00262 to 0.00000, saving model to weights.hdf5\nEpoch 15/100\n260/260 [==============================] - 107s 413ms/step - loss: 1.9746e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0041 - val_categorical_accuracy: 0.9980\n\nEpoch 00015: val_loss did not improve from 0.00000\nEpoch 16/100\n260/260 [==============================] - 107s 412ms/step - loss: 1.5523e-04 - categorical_accuracy: 1.0000 - val_loss: 5.3644e-07 - val_categorical_accuracy: 0.9960\n\nEpoch 00016: val_loss improved from 0.00000 to 0.00000, saving model to weights.hdf5\nEpoch 17/100\n260/260 [==============================] - 107s 411ms/step - loss: 0.0020 - categorical_accuracy: 0.9990 - val_loss: 0.0299 - val_categorical_accuracy: 0.9583\n\nEpoch 00017: val_loss did not improve from 0.00000\nEpoch 18/100\n260/260 [==============================] - 108s 414ms/step - loss: 0.2871 - categorical_accuracy: 0.9269 - val_loss: 15.9999 - val_categorical_accuracy: 0.1627\n\nEpoch 00018: val_loss did not improve from 0.00000\nEpoch 19/100\n260/260 [==============================] - 107s 410ms/step - loss: 0.0267 - categorical_accuracy: 0.9925 - val_loss: 6.8671 - val_categorical_accuracy: 0.3909\n\nEpoch 00019: val_loss did not improve from 0.00000\nEpoch 20/100\n260/260 [==============================] - 107s 411ms/step - loss: 0.0119 - categorical_accuracy: 0.9962 - val_loss: 4.6257 - val_categorical_accuracy: 0.4742\n\nEpoch 00020: val_loss did not improve from 0.00000\nEpoch 21/100\n260/260 [==============================] - 107s 411ms/step - loss: 0.0011 - categorical_accuracy: 1.0000 - val_loss: 0.3345 - val_categorical_accuracy: 0.8651\n\nEpoch 00021: val_loss did not improve from 0.00000\nEpoch 22/100\n260/260 [==============================] - 107s 411ms/step - loss: 6.1588e-04 - categorical_accuracy: 0.9998 - val_loss: 1.6175e-04 - val_categorical_accuracy: 0.9643\n\nEpoch 00022: val_loss did not improve from 0.00000\nEpoch 23/100\n260/260 [==============================] - 107s 413ms/step - loss: 3.0779e-04 - categorical_accuracy: 1.0000 - val_loss: 0.0029 - val_categorical_accuracy: 0.9921\n\nEpoch 00023: val_loss did not improve from 0.00000\nEpoch 24/100\n260/260 [==============================] - 107s 411ms/step - loss: 3.3981e-04 - categorical_accuracy: 1.0000 - val_loss: 5.6189e-05 - val_categorical_accuracy: 0.9960\n\nEpoch 00024: val_loss did not improve from 0.00000\nEpoch 25/100\n260/260 [==============================] - 107s 410ms/step - loss: 2.0860e-04 - categorical_accuracy: 1.0000 - val_loss: 7.5251e-07 - val_categorical_accuracy: 1.0000\n\nEpoch 00025: val_loss did not improve from 0.00000\nEpoch 26/100\n260/260 [==============================] - 107s 411ms/step - loss: 1.0357e-04 - categorical_accuracy: 1.0000 - val_loss: 2.8982e-06 - val_categorical_accuracy: 1.0000\n\nEpoch 00026: val_loss did not improve from 0.00000\nEpoch 00026: early stopping\nFound 4160 validated image filenames belonging to 52 classes.\nloss: 7.227046125990455e-07\ncategorical_accuracy: 1.0\nFound 572 validated image filenames belonging to 52 classes.\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        11\n           1       1.00      1.00      1.00        11\n           2       1.00      1.00      1.00        11\n           3       1.00      1.00      1.00        11\n           4       1.00      1.00      1.00        11\n           5       1.00      1.00      1.00        11\n           6       1.00      1.00      1.00        11\n           7       1.00      1.00      1.00        11\n           8       1.00      1.00      1.00        11\n           9       1.00      1.00      1.00        11\n          10       1.00      1.00      1.00        11\n          11       1.00      1.00      1.00        11\n          12       1.00      1.00      1.00        11\n          13       1.00      1.00      1.00        11\n          14       1.00      1.00      1.00        11\n          15       1.00      1.00      1.00        11\n          16       1.00      1.00      1.00        11\n          17       1.00      1.00      1.00        11\n          18       1.00      1.00      1.00        11\n          19       1.00      1.00      1.00        11\n          20       1.00      1.00      1.00        11\n          21       1.00      1.00      1.00        11\n          22       1.00      1.00      1.00        11\n          23       1.00      1.00      1.00        11\n          24       1.00      1.00      1.00        11\n          25       1.00      1.00      1.00        11\n          26       1.00      1.00      1.00        11\n          27       1.00      1.00      1.00        11\n          28       1.00      1.00      1.00        11\n          29       1.00      1.00      1.00        11\n          30       1.00      1.00      1.00        11\n          31       1.00      1.00      1.00        11\n          32       1.00      1.00      1.00        11\n          33       1.00      1.00      1.00        11\n          34       1.00      1.00      1.00        11\n          35       1.00      1.00      1.00        11\n          36       1.00      1.00      1.00        11\n          37       1.00      1.00      1.00        11\n          38       1.00      1.00      1.00        11\n          39       1.00      1.00      1.00        11\n          40       1.00      1.00      1.00        11\n          41       1.00      1.00      1.00        11\n          42       1.00      1.00      1.00        11\n          43       1.00      1.00      1.00        11\n          44       1.00      1.00      1.00        11\n          45       1.00      1.00      1.00        11\n          46       1.00      1.00      1.00        11\n          47       1.00      1.00      1.00        11\n          48       1.00      1.00      1.00        11\n          49       1.00      1.00      1.00        11\n          50       1.00      1.00      1.00        11\n          51       1.00      1.00      1.00        11\n\n   micro avg       1.00      1.00      1.00       572\n   macro avg       1.00      1.00      1.00       572\nweighted avg       1.00      1.00      1.00       572\n samples avg       1.00      1.00      1.00       572\n\n"
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}